{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c924f7c-8199-4a4c-b1d9-d6e756bf022e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import configparser\n",
    "import datetime\n",
    "import nbimporter\n",
    "from Functions import *\n",
    "from Daily_etl import *\n",
    "from SQL import *\n",
    "from Connection_to_pgAdmin4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd8c68d-e797-4c80-8023-d61c49c08e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip install psycopg2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#installation \n",
    "#by default you might not have yahoo finance/ library, or psycopg2, or  nbimporternbimporter so you may have to install one\n",
    "'''pip install yfinance'''\n",
    "'''pip install nbimporter'''\n",
    "'''pip install psycopg2'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dda4cb3-bf87-4950-9c72-a540be8a1642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#schema variables \n",
    "#defining these as they will be used for development of sql queries\n",
    "#source = 'Source'\n",
    "#staging='Staging'\n",
    "#dimensions='Dimension'\n",
    "#facts='Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d61c10-4e47-4082-bf1a-89d9c6a38b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is a sample test and will be used for testing only. \n",
    "#It utilises yfinance library. It takes \"Ticker\" symbol then returns the ticker information. \n",
    "#Fetch data for a single stock symbol\n",
    "#This is used to get financial information on stock market from yahoo finance using ticker as test \n",
    "\n",
    "stock = yf.Ticker(\"AAPL\")\n",
    "hist = stock.history(period=\"25y\")  # Fetches one month of historical data\n",
    "\n",
    "#print(hist)\n",
    "#If you want to see the result just uncomment the print statement.\n",
    "#This was a test that was run to ensure that the code is able to work on one ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86225a9-742f-4789-9414-307d87c46977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn order to get the data into postgreSQL database there are steps that i am following \\n\\n1 In order to download information on a company I will need their ticker name. \\n\\nFor example company like APPLE their ticker symbol would be AAPL. Their ticker name will be used to feth data based on them. The same applies to the rest of the companies on LSEG. \\n\\nThe code developed below will use ticker symbol to fetch data per company. Because there is yfinance library available that will help with downloading historical data , \\nI will utilise that by using ticker symbol per company, Therefor it is important to use ticker symbol to extract a companies historical data.\\n\\nThere is a file downloaded from https://www.eoddata.com/stockquote/LSE/FEUI.html and an account is required to obtain it.\\nThis file holds information on companies and their tickers.\\nThis is technically easier as there will be less time spent trying to obtain ticker name from stock market.\\n\\n\\n**************************\\nNeed this to go into log book\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In order to get the data into postgreSQL database there are steps that i am following \n",
    "\n",
    "1 In order to download information on a company I will need their ticker name. \n",
    "\n",
    "For example company like APPLE their ticker symbol would be AAPL. Their ticker name will be used to feth data based on them. The same applies to the rest of the companies on LSEG. \n",
    "\n",
    "The code developed below will use ticker symbol to fetch data per company. Because there is yfinance library available that will help with downloading historical data , \n",
    "I will utilise that by using ticker symbol per company, Therefor it is important to use ticker symbol to extract a companies historical data.\n",
    "\n",
    "There is a file downloaded from https://www.eoddata.com/stockquote/LSE/FEUI.html and an account is required to obtain it.\n",
    "This file holds information on companies and their tickers.\n",
    "This is technically easier as there will be less time spent trying to obtain ticker name from stock market.\n",
    "\n",
    "\n",
    "**************************\n",
    "Need this to go into log book\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3137d5d-d21b-49b1-91dc-4ea92990d789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Moving data from file to the database\n",
    "#I have now downloaded a file from https://www.eoddata.com/stockquote/LSE/FEUI.html \n",
    "#The file contains information on tickers and symbols. \n",
    "#I will now pushed information from the file into database.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef7430a7-40c3-4d62-87ec-204ad31d7c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#*******\\n\\n\\n#path to the text file \\nfile_path = \"lse.txt\"\\n\\n#SQL query to insert data into the table\\ninsert_query = \"\"\"\\nINSERT INTO source.ticker_and_name (symbol, Description)\\nVALUES (%s, %s);\\n\"\"\"\\n\\n#connection to the database and creates a cursor\\nconnection = connect_to_database()\\ncursor = connection.cursor()\\n\\ntry:\\n    # Opens the file for reading\\n    with open(file_path, \"r\") as file:\\n        # Reads each line in the file\\n        for line in file:\\n            # Splits each line into columns based on a delimiter (e.g., tab)\\n            parts = line.strip().split(\\'\\t\\')  # Assumes tab as the delimiter\\n\\n            # Check if the line contains the expected number of columns\\n            if len(parts) == 2:  # Assuming 2 columns (Symbol and Description)\\n                symbol, description = parts\\n\\n                # Executes the INSERT query for each row\\n                cursor.execute(insert_query, (symbol, description))\\n\\n    # Commits the changes to the database\\n    connection.commit()\\n    print(\"Data inserted successfully.\")\\n\\nexcept (Exception, psycopg2.Error) as error:\\n    print(f\"Error: {error}\")\\n    if connection:\\n        connection.rollback()\\n\\nfinally:\\n    # Closes the cursor and connection\\n    if cursor:\\n        cursor.close()\\n    if connection:\\n        connection.close()\\n\\n#*******\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert data into the table from text file so this can used at a later stage.\n",
    "#This is being stored in a table so that it can be kept for records. \n",
    "#This will also aid in data transformation\n",
    "\n",
    "#this code will be commented out so incase if run by mistake it does not cause duplications, or rewrites the same table and you may lose data.\n",
    "#You will need to remove the ******* and uncomment the code. \n",
    "#SQL REFERENCE \n",
    "##Reference cell\n",
    "\n",
    "\n",
    "'''\n",
    "#*******\n",
    "\n",
    "\n",
    "#path to the text file \n",
    "file_path = \"lse.txt\"\n",
    "\n",
    "#SQL query to insert data into the table\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO source.ticker_and_name (symbol, Description)\n",
    "VALUES (%s, %s);\n",
    "\"\"\"\n",
    "\n",
    "#connection to the database and creates a cursor\n",
    "connection = connect_to_database()\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try:\n",
    "    # Opens the file for reading\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Reads each line in the file\n",
    "        for line in file:\n",
    "            # Splits each line into columns based on a delimiter (e.g., tab)\n",
    "            parts = line.strip().split('\\t')  # Assumes tab as the delimiter\n",
    "\n",
    "            # Check if the line contains the expected number of columns\n",
    "            if len(parts) == 2:  # Assuming 2 columns (Symbol and Description)\n",
    "                symbol, description = parts\n",
    "\n",
    "                # Executes the INSERT query for each row\n",
    "                cursor.execute(insert_query, (symbol, description))\n",
    "\n",
    "    # Commits the changes to the database\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully.\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(f\"Error: {error}\")\n",
    "    if connection:\n",
    "        connection.rollback()\n",
    "\n",
    "finally:\n",
    "    # Closes the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "\n",
    "#*******\n",
    "'''\n",
    "\n",
    "\n",
    "#Now that ticker is saved one test will be run below to see what data it holds and get the sape of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e4634-255b-433d-a8bd-f147c6dfc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now that I have ticker and desription of the companies, i will test the sybmols by giving it to yfinance library to fetch infotmation on in.\n",
    "#Below is an example of the ticker AAPL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a509a6d1-d506-4ca3-8e38-98287e0d413a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for AAPL\n",
      "Name: Apple Inc.\n",
      "Industry: Consumer Electronics\n",
      "Sector: Technology\n",
      "Country: United States\n",
      "Market Cap: 2603349704704\n"
     ]
    }
   ],
   "source": [
    "#The code below just gets the shape of the metadata on company\n",
    "\n",
    "\n",
    "# Create a Ticker object for the symbol you want to get metadata for\n",
    "symbol = \"AAPL\"  # change it for sampling with the symbol you're want in\n",
    "ticker = yf.Ticker(symbol)\n",
    "\n",
    "# Access the metadata attributes\n",
    "metadata = ticker.info\n",
    "\n",
    "\n",
    "\n",
    "#***************** \n",
    "#more can be printed by removing the comment from the print statament below.\n",
    "#print (metadata)\n",
    "print(\"Metadata for\", symbol)\n",
    "print(\"Name:\", metadata[\"shortName\"])\n",
    "print(\"Industry:\", metadata[\"industry\"])\n",
    "print(\"Sector:\", metadata[\"sector\"])\n",
    "print(\"Country:\", metadata[\"country\"])\n",
    "print(\"Market Cap:\", metadata[\"marketCap\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1191c0-438a-4205-81fa-d92ac23544cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********\n",
    "\n",
    "#Now from the previous test I can get information on tickers I now need to create a table that will hold the information on finance of the companies.\n",
    "#Below SQL creats a table in the source schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dca04-1adc-4c0a-b59c-80660f8bead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********\n",
    "\n",
    "#Now using the information provided by the yfinance library, I will use ticker.history method to call each ticker, and store their information on table that was created above. \n",
    "#Below is a function that will be used to fetch data from the yfinance library, because there are so manu columns that I do not need, I will limit the number of columns to fetch too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c85e5220-46c7-47e6-a131-67dcd32eb220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Taking each symbole from the lse.txt file that was downloaded earlier, \n",
    "#looping through 1st 100 in the list at a time and fetching records from yahoo finance yfinance library from 2005\n",
    "#path to file containing symbols\n",
    "#Read and process the file\n",
    " \n",
    "'''\n",
    "It will first read the file\n",
    "and stores the sybmols inside an empty array. \n",
    "\n",
    "ensuring the that there are no nulls, or integar values. \n",
    "\n",
    "using the stored symbols get companies information since 2005 till today. \n",
    "\n",
    "Once records are fetched Then inserting into the table created above\n",
    "\n",
    "In order to mange hitting the api limits for yfinance library I had to complete this task in batch of a hundred.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ebc64d-0600-49b1-b0f4-9a6d8e40776b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Path to file containing symbols\\nfile_path = \"lse.txt\"\\nsymbols = []\\n\\n# Flag to start adding symbols after finding \"02NG.L\"\\nstart_adding = False\\n\\nwith open(file_path, \"r\") as file:\\n    next(file)  # Skip the header\\n    for line in file:\\n        symbol = line.split()[0].strip()\\n        # Skip invalid symbols\\n        if symbol in (\\'null\\', \\'0.0\\', \\'\\'):\\n            continue\\n        if symbol == \"02NG.L\":\\n            start_adding = True\\n        if start_adding:\\n            symbols.append(symbol)\\n\\n#SQL INSERT statement here\\ninsert_query = \"\"\"\\n    INSERT INTO source.historical_stock_data (Date, Open, High, Low, Close, Volume, Dividends, Stock_Splits, Symbol)\\n    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\\n\"\"\"\\n\\n# Process symbols in batches of 100\\nbatch_size = 100\\nfor i in range(0, len(symbols), batch_size):\\n    batch_symbols = symbols[i:i + batch_size]\\n    all_historical_data = pd.DataFrame()\\n\\n    for symbol in batch_symbols:\\n        historical_data = fetch_historical_data(symbol)\\n        if not historical_data.empty:\\n            all_historical_data = pd.concat([all_historical_data, historical_data])\\n\\n    if not all_historical_data.empty:\\n        records_to_insert = all_historical_data.to_records(index=False).tolist()\\n\\n        record_count = 0\\n        for record in records_to_insert:\\n            # Handle NaN values and convert them to None\\n            modified_record = tuple([None if pd.isna(value) else value for value in record])\\n\\n            execute_sql_query(insert_query, modified_record)\\n            record_count += 1\\n\\n        print(f\"Batch {i//batch_size + 1}: Inserted {record_count} records.\")\\n    else:\\n        print(f\"Batch {i//batch_size + 1}: No data to insert.\")\\n        \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*********************\n",
    "#WARNING IF YOU RUN THIS CODE IT WILL START POPULATING THE DATABASE THAT WILL RUN FOR FEW DAYS ENSURE YOU HAVE THE RIGHT SPACE AND ENVIRONMENT  \n",
    "#AND ENSURE THIS CODE REMAIN COMMENTED.\n",
    "#Functions used \n",
    "#SQL REFERENCE A\n",
    "##Reference cell A\n",
    "#*********************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# Path to file containing symbols\n",
    "file_path = \"lse.txt\"\n",
    "symbols = []\n",
    "\n",
    "# Flag to start adding symbols after finding \"02NG.L\"\n",
    "start_adding = False\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    next(file)  # Skip the header\n",
    "    for line in file:\n",
    "        symbol = line.split()[0].strip()\n",
    "        # Skip invalid symbols\n",
    "        if symbol in ('null', '0.0', ''):\n",
    "            continue\n",
    "        if symbol == \"02NG.L\":\n",
    "            start_adding = True\n",
    "        if start_adding:\n",
    "            symbols.append(symbol)\n",
    "\n",
    "#SQL INSERT statement here\n",
    "insert_query = \"\"\"\n",
    "    INSERT INTO source.historical_stock_data (Date, Open, High, Low, Close, Volume, Dividends, Stock_Splits, Symbol)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Process symbols in batches of 100\n",
    "batch_size = 100\n",
    "for i in range(0, len(symbols), batch_size):\n",
    "    batch_symbols = symbols[i:i + batch_size]\n",
    "    all_historical_data = pd.DataFrame()\n",
    "\n",
    "    for symbol in batch_symbols:\n",
    "        historical_data = fetch_historical_data(symbol)\n",
    "        if not historical_data.empty:\n",
    "            all_historical_data = pd.concat([all_historical_data, historical_data])\n",
    "\n",
    "    if not all_historical_data.empty:\n",
    "        records_to_insert = all_historical_data.to_records(index=False).tolist()\n",
    "\n",
    "        record_count = 0\n",
    "        for record in records_to_insert:\n",
    "            # Handle NaN values and convert them to None\n",
    "            modified_record = tuple([None if pd.isna(value) else value for value in record])\n",
    "\n",
    "            execute_sql_query(insert_query, modified_record)\n",
    "            record_count += 1\n",
    "\n",
    "        print(f\"Batch {i//batch_size + 1}: Inserted {record_count} records.\")\n",
    "    else:\n",
    "        print(f\"Batch {i//batch_size + 1}: No data to insert.\")\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e75b8-60ab-4e2c-92fc-18d09cbdb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "The data is now added to the table. \n",
    "The next step is to get company information.\n",
    "This will be achieved using yfinance library method yf.info\n",
    "\n",
    "There is an example below.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f37e568-9eb3-40d5-a173-cac10c3dea43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Using symbols gets information on company eg ticker for Apple, \n",
    "symbol = \"AAPL\"  # Change with the symbol you're want in\n",
    "ticker = yf.Ticker(symbol)\n",
    "\n",
    "# Access the metadata attributes\n",
    "metadata = ticker.info\n",
    "\n",
    "\n",
    "#just uncomment the print statement to see information on company.\n",
    "#print (metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6969314d-6c98-4a31-af8a-4b0df3686be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#The next step is to get information on companies, as tested above, yf.info method will be used to pull information from yfinance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db784068-722b-4aab-9b98-e2a52aee8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************\n",
    "#This code uses both function above and loops through symbols in bathc of 100 and fetches their information \n",
    "#Then once information is fetched it is then inserted into the the respective table\n",
    "#This code will be commented out. To avoid running by error and rewriting the entire table or causing duplication.\n",
    "#SQL REFERENCE B\n",
    "#Reference cell B\n",
    "#*****************\n",
    "'''\n",
    "\n",
    "with open(\"lse.txt\", \"r\", encoding='utf-8') as file:\n",
    "    next(file)  # Skip the header line\n",
    "    symbols = [line.split('\\t')[0].strip() for line in file]\n",
    "\n",
    "batch_size = 100\n",
    "error_symbols = []\n",
    "\n",
    "for i in range(0, len(symbols), batch_size):\n",
    "    batch_symbols = symbols[i:i + batch_size]\n",
    "    for symbol in batch_symbols:\n",
    "        info_df = fetch_info_data(symbol)\n",
    "        if info_df is not None and not info_df.empty:\n",
    "            for _, row in info_df.iterrows():\n",
    "                insert_customer_data(row)\n",
    "        else:\n",
    "            error_symbols.append(symbol)  # Append symbol to error list if data fetch fails\n",
    "\n",
    "    print(f\"Processed batch {i // batch_size + 1}/{len(symbols) // batch_size + 1}\")\n",
    "\n",
    "\n",
    "print(\"All data processed and inserted into source.s_customer\")\n",
    "if error_symbols:\n",
    "    with open('s_customer_error_symbols.csv', 'w') as f:\n",
    "        for symbol in error_symbols:\n",
    "            f.write(f\"{symbol}\\n\")\n",
    "    print(f\"Symbols with errors written to 's_customer_error_symbols.csv'\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06186e03-bfcc-408f-84df-032007f89997",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The above code has run and populated the table needed to be populated. \n",
    "\n",
    "The next step is to generate a data dimensions. \n",
    "Date dimension is important in order to get STAR SCHEMA the right way for data process, therefor the below code will generate dates and related information, \n",
    "such as fisical year, weekends, holidays, quarters.\n",
    "\n",
    "and a furthur function to insert the data into date table\n",
    "\n",
    "The table to store the infromation has been already generated.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bdae13-c51a-4c1a-a60f-e002a263a74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef insert_date_dimension_row(row):\\n    query = \"\"\"\\n    INSERT INTO source.s_date \\n    (Date, Year, Quarter, Month, Week, Day, DayOfWeek, IsWeekend, IsHoliday, FiscalYear, FiscalQuarter, FiscalMonth) \\n    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\\n    \"\"\"\\n    # Formatting the Date to string if it\\'s in datetime format\\n    date_str = row[\\'Date\\'].strftime(\\'%Y-%m-%d\\') if pd.notnull(row[\\'Date\\']) else None\\n\\n    params = (\\n        date_str, row[\\'Year\\'], row[\\'Quarter\\'], row[\\'Month\\'], row[\\'Week\\'], row[\\'Day\\'], \\n        row[\\'DayOfWeek\\'], row[\\'IsWeekend\\'], row[\\'IsHoliday\\'], row[\\'FiscalYear\\'], \\n        row[\\'FiscalQuarter\\'], row[\\'FiscalMonth\\']\\n    )\\n\\n    # Execute the SQL query\\n    execute_sql_query(query, params)\\n\\n# Generate the date dimension DataFrame\\nstart_date = datetime.date(2005, 1, 1)\\nend_date = datetime.date(2050, 12, 31)\\ndate_dimension = generate_date_dimension(start_date, end_date)\\n\\n# Iterate through each row of  DataFrame and insert it\\nfor index, row in date_dimension.iterrows():\\n    insert_date_dimension_row(row)\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*****************\n",
    "#This code uses the function created generate_date_dimension, and the result of that function is then pushed into the database.\n",
    "#This code does not need to be run regularley so will comment it out. \n",
    "#SQL REFERENCE B\n",
    "#Reference cell C\n",
    "#*****************\n",
    "\n",
    "'''\n",
    "\n",
    "def insert_date_dimension_row(row):\n",
    "    query = \"\"\"\n",
    "    INSERT INTO source.s_date \n",
    "    (Date, Year, Quarter, Month, Week, Day, DayOfWeek, IsWeekend, IsHoliday, FiscalYear, FiscalQuarter, FiscalMonth) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    # Formatting the Date to string if it's in datetime format\n",
    "    date_str = row['Date'].strftime('%Y-%m-%d') if pd.notnull(row['Date']) else None\n",
    "\n",
    "    params = (\n",
    "        date_str, row['Year'], row['Quarter'], row['Month'], row['Week'], row['Day'], \n",
    "        row['DayOfWeek'], row['IsWeekend'], row['IsHoliday'], row['FiscalYear'], \n",
    "        row['FiscalQuarter'], row['FiscalMonth']\n",
    "    )\n",
    "\n",
    "    # Execute the SQL query\n",
    "    execute_sql_query(query, params)\n",
    "\n",
    "# Generate the date dimension DataFrame\n",
    "start_date = datetime.date(2005, 1, 1)\n",
    "end_date = datetime.date(2050, 12, 31)\n",
    "date_dimension = generate_date_dimension(start_date, end_date)\n",
    "\n",
    "# Iterate through each row of  DataFrame and insert it\n",
    "for index, row in date_dimension.iterrows():\n",
    "    insert_date_dimension_row(row)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd07520a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock = yf.Ticker('0JHR.L')\n",
    "info = stock.history('max')\n",
    "#print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec10b4e-35d0-474a-9a1d-bf232031e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Collectiong stock information of symbols that show no stock listing data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4031268e-23f1-48f5-a810-fe0b073626c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#*********************\n",
    "#AND ENSURE THIS CODE REMAIN COMMENTED.\n",
    "#this code is populating the missing data for some companies\n",
    "#SQL REFERENCE A\n",
    "#Reference cell G\n",
    "#*********************\n",
    "\n",
    "'''\n",
    "symbols = [\n",
    "\"AAPL\",\n",
    "\"HKLB.L\",\n",
    "\"IEBB.L\",\n",
    "\"LTHP.L\",\n",
    "\"ICOV.L\",\n",
    "\"IESP.L\",\n",
    "\"MCON.L\",\n",
    "\"EURO.L\",\n",
    "\"FEUD.L\",\n",
    "\"GAID.L\",\n",
    "\"IEX5.L\",\n",
    "\"PUIG.L\",\n",
    "\"TFGS.L\"\n",
    "]  # \n",
    "\n",
    "for symbol in symbols:\n",
    "    data = fetch_missing_symbol_data(symbol)\n",
    "    if not data.empty:\n",
    "        records_to_insert = [\n",
    "            (\n",
    "                row['Date'], row['Open'], row['High'], row['Low'], row['Close'], row['Volume'],\n",
    "                row['Dividends'], row['Stock Splits'], row['Symbol']\n",
    "            )\n",
    "            for index, row in data.iterrows()\n",
    "        ]\n",
    "        \n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO source.historical_stock_data (Date, Open, High, Low, Close, Volume, Dividends, Stock_Splits, Symbol)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        \n",
    "        # Execute SQL query for each record\n",
    "        for record in records_to_insert:\n",
    "            execute_sql_query(insert_query, record)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4507af-7ed8-4495-a539-8964658ad55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The gaps of missing data has now been completed\n",
    "There is stock information available now source table. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306dd2d-d614-4491-992b-b2e45468dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Now since the code part is complete, next thing is to fill the stock data  based on reading table from facts \"facts.dates_of_stock_info\" that will\n",
    "compare the last date to todays date and if it is not the same it will fetch the data and append to source and insert it into historical stock data table.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
